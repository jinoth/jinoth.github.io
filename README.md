# Jinoth Kumar - Data Scientist Portfolio

> Personal portfolio website showcasing my data science projects, technical skills, and professional experience.

[![GitHub](https://img.shields.io/badge/github-portfolio-blue)](https://github.com/jinoth)
[![LinkedIn](https://img.shields.io/badge/linkedin-connect-0077B5)](https://www.linkedin.com/in/jinothkumar)

---

## üöÄ About Me

Data Scientist with 4+ years of professional experience specializing in big data engineering and location analytics. Expert in PySpark, AWS EMR, Databricks, and distributed computing for processing terabytes of GPS data. Currently at **KDDI Corporation** developing segmentation algorithms and targeting logic for location-based intelligence across multiple enterprise clients including retail, transportation, and manufacturing sectors.

**Key Expertise:**
- Large-scale Data Engineering with Databricks, AWS EMR, and PySpark
- Python-based AI/ML Pipeline Development: Data Extraction, Preprocessing, Feature Engineering, and Visualization
- Pipeline Construction, Data Modeling, and View Creation using Azure Synapse
- Intuitive Dashboard Development with Power BI and Tableau
- High-Speed Analysis of Terabyte-Scale GPS Data using Spark Processing
- Data Warehouse Concepts (ETL/ELT, Star Schema, Scalable Data Design)
- Rapid Learning and Practical Application of New Cloud Technologies and Tools

**Location:** Tokyo, Japan üáØüáµ  
**Languages:** Japanese (JLPT N2 - Listening: 100% | Pursuing N1), English (Professional Working Proficiency)

---

## üíº Featured Projects

### üè• Healthcare Analytics & Location-Based Advertising Intelligence - KDDI Corporation
**Period:** 2024.04 - Present (21 months)  
**Role:** Data Analyst - Platform Business Division, Data Science Group (DSG)  
**Technologies:** PySpark, Apache Spark, AWS EMR, Databricks, Python, SQL, Tableau, Tableau Prep, AWS EC2, AWS S3, KDDI Location Analyzer (KLA)

**Key Achievements:**
- Built PySpark pipelines on AWS EMR and Databricks processing terabytes of GPS data from au devices for multiple clients (jeki, NewDays, Hitachi Seisakusho)
- Developed and expanded targeting segmentation algorithms from 7 to 15+ advanced segments
- Built Tableau dashboards and interactive heatmaps visualizing visitor movement, demographics, and behavioral patterns
- Delivered precision targeting solutions for 236+ digital signage screens and retail locations
- Processed privacy-compliant statistical aggregation on massive location datasets
- Designed Tableau dashboards for health metrics tracking (AU Wellness project)

### üî• AI Wildfire Prediction Research Pipeline
**Period:** 2023.12 - 2024.03 (4 months)  
**Role:** ML Engineer  
**Technologies:** Python, Flask, TensorFlow, Kedro Pipelines, Apache Airflow, Docker, OpenCV, Pandas, NumPy

**Key Achievements:**
- Refactored AI research and development logic from researcher-created models
- Analyzed machine-learning models and modified existing source code
- Built system pipelines using Kedro and Apache Airflow
- Created Docker images for production deployment

### üìä BI Dashboard Operations & Automation
**Period:** 2023.07 - 2023.11 (5 months)  
**Role:** Data Analyst  
**Technologies:** Python, SQL, VBA, Azure Data Factory, Azure DevOps, Logic Apps, Power BI, Tableau, SQL Server

**Key Achievements:**
- Automated operations using Python and VBA macros for Excel automation
- Created and managed pipelines: data flows, pipeline testing, trigger configuration
- Released pipelines and data flows in Azure DevOps, approved pull requests
- Troubleshot Power BI and Tableau dashboard issues
- Created comprehensive documentation: reports, test reports, procedure manuals

[View all projects ‚Üí](https://jinoth.github.io)

---

## üõ†Ô∏è Technical Skills

### Programming Languages
- **Expert:** Python, SQL
- **Advanced:** Power Query
- **Intermediate:** Java, VBA

### Cloud & Data Platforms
- **Azure:** Synapse Analytics, Data Factory, DevOps, Power Platform
- **AWS:** EC2, S3, EMR
- **Databases:** SQL Server (SSMS), MySQL

### Data Science & ML
- **Libraries:** Pandas, NumPy, Scikit-learn, TensorFlow, PySpark
- **Visualization:** Matplotlib, Seaborn, Plotly, Folium
- **BI Tools:** Power BI, Tableau, Tableau Prep

### Development Tools
- Jupyter Notebook, VS Code, Git, Docker, Kedro, Apache Airflow

---

## üéì Certifications

- **AWS Certified Cloud Practitioner** (May 2023)
- **Japanese Language Proficiency Test JLPT N2** (December 2024)
- **Japanese Language Proficiency Test JLPT N3** (December 2020)
- **Python Programming for Data Science & ML** (March 2020)
- **Advanced Java Programming** (July 2018)

### Recent Learning (2022-2025)
- PySpark - Apache Spark Programming (14 hours)
- Microsoft Power BI - Data Modeling (10.5 hours)
- AWS EC2 & Fundamentals (6 hours)
- Tableau Masterclass (8 hours)
- Data Warehouse Development (23 hours total)

---

## üì´ Contact

- **Location:** Tokyo, Japan üáØüáµ
- **Email:** [jinoth2112@gmail.com](mailto:jinoth2112@gmail.com)
- **LinkedIn:** [linkedin.com/in/jinothkumar](https://www.linkedin.com/in/jinothkumar)
- **GitHub:** [github.com/jinoth](https://github.com/jinoth)
- **Languages:** Japanese (JLPT N2 - Listening: 100% | Pursuing N1), English (Professional Working Proficiency)

### Contact Form

The portfolio includes an interactive contact form that generates professional email templates. **Required fields:**
- Name *
- Company Name *
- Website Link *
- Project/Position Requirements *

Fill in your information to generate a contact email template.

---

## üåê Website

Visit my portfolio: **[https://jinoth.github.io](https://jinoth.github.io)**

Built with:
- React 18
- Tailwind CSS
- Lucide Icons
- Vanilla JavaScript

---

## üìù License

¬© 2025 Jinoth Kumar. All rights reserved.

---

## üîÑ Updates

- **Jan 2025** - Portfolio website launched
- **Dec 2024** - Achieved JLPT N2 certification
- **Apr 2024** - Started at KDDI Corporation

---

### ‚≠ê If you like my work, consider giving this repo a star!

**Available for:**
- Data Science Consulting
- Azure Cloud Solutions
- BI Development Projects
- Machine Learning Implementation
- Location Analytics & GPS Data Processing
- Big Data Engineering with PySpark & Databricks
